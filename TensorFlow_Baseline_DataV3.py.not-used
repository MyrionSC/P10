from __future__ import absolute_import, division, print_function

import tensorflow as tf
import numpy as np

import os
import sys

COLUMN_NAMES = ['meters_segment', 'categoryid', 'month', 'weekday', 'min_from_midnight', 'air_temperature', 'tailwind_magnitude', 'incline_angle']
FILE_NAME = "data\\BaselineData3.csv"
fc = tf.feature_column
tf.logging.set_verbosity(tf.logging.INFO)

def _parse_csv(rows_string_tensor):
    """Takes the string input tensor and returns tuple of (features, labels)"""
    # Last dim is the label
    num_features = len(COLUMN_NAMES)
    num_columns = num_features + 1
    columns = tf.decode_csv(rows_string_tensor, record_defaults=[[0.0], [0], [0], [0], [0], [0.0], [0.0], [0.0], [0.0]])
    features = dict(zip(COLUMN_NAMES, columns[:num_features]))
    labels = tf.cast(columns[num_features], tf.float32)
    return features, labels

def input_fn(is_training):
    """An input function"""
    #complete_dataset = tf.contrib.data.CsvDataset(FILE_NAME, [tf.float32, tf.float32, tf.float32, tf.int32, tf.int32,
    #                                                          tf.int32, tf.int32, tf.float32], header=True)

    dataset = tf.data.TextLineDataset([FILE_NAME])
    dataset = dataset.skip(1)
    dataset = dataset.map(_parse_csv, num_parallel_calls = 12)

    if is_training:
        dataset = dataset.skip(3618252)
        dataset = dataset.shuffle(150)
        dataset = dataset.cache()
        dataset = dataset.repeat(10)
    else:
        dataset = dataset.take(3618252)

    dataset = dataset.batch(256)

    return dataset

def mean_absolute_error(labels, predictions):
    pred_values = predictions['predictions']
    return {'mean_absolute_error': tf.metrics.mean_absolute_error(labels, pred_values)}

def mean_relative_error(labels, predictions):
    pred_values = predictions['predictions']
    return {'mean_relative_error': tf.metrics.mean_relative_error(labels, pred_values)}

def mean_squared_error(labels, predictions):
    pred_values = predictions['predictions']
    return {'mean_squared_error': tf.metrics.mean_squared_error(labels, pred_values)}

meters_segment_bound, min_from_midnight_bound, air_temperature_bound, tailwind_magnitude_bound, incline_angle_bound = [], [], [], [], []
for i in range(0, 10025, 25):
    meters_segment_bound.append(i)
for i in range(0, 1470, 30):
    min_from_midnight_bound.append(i)
for i in range(-20, 45, 5):
    air_temperature_bound.append(i)
for i in range(-26, 27, 1):
    tailwind_magnitude_bound.append(i)
for i in range(-60, 85, 5):
    incline_angle_bound.append(i)
	
meters_segment_c = fc.bucketized_column(fc.numeric_column(key="meters_segment", dtype=tf.float32), meters_segment_bound)
air_temperature_c = fc.bucketized_column(fc.numeric_column(key="air_temperature", dtype=tf.float32), air_temperature_bound)
tailwind_magnitude_c = fc.bucketized_column(fc.numeric_column(key="tailwind_magnitude", dtype=tf.float32), tailwind_magnitude_bound)
incline_angle_c = fc.bucketized_column(fc.numeric_column(key="incline_angle", dtype=tf.float32), incline_angle_bound)
categoryid_c = fc.numeric_column(key="categoryid", dtype=tf.int32)
month_c = fc.numeric_column(key="month", dtype=tf.int32)
weekday_c = fc.numeric_column(key="weekday", dtype=tf.int32)
min_from_midnight_c = fc.bucketized_column(fc.numeric_column(key="min_from_midnight", dtype=tf.int32), min_from_midnight_bound)
estimator = tf.estimator.LinearRegressor(feature_columns=[meters_segment_c, categoryid_c, month_c, weekday_c, min_from_midnight_c,
                                                         air_temperature_c, tailwind_magnitude_c, incline_angle_c])

estimator = tf.contrib.estimator.add_metrics(estimator, mean_absolute_error)
#estimator = tf.contrib.estimator.add_metrics(estimator, mean_relative_error)
estimator = tf.contrib.estimator.add_metrics(estimator, mean_squared_error)

estimator.train(input_fn=lambda: input_fn(True))
print("Done training!")
metrics = estimator.evaluate(input_fn=lambda: input_fn(False))
preds = estimator.predict(input_fn=lambda: input_fn(False))
predictions = np.array([item['predictions'][0] for item in preds])

for i in metrics:
    print(i, metrics[i])

print("Done!")
